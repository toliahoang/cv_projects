import torch
import os
from torch import nn
import matplotlib.pyplot as plt
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"
from tqdm.auto import tqdm
import torchvision
from torchvision import datasets
from torchvision.transforms import ToTensor
from torch.utils.data import DataLoader
from pytorch_practical.helper_functions import accuracy_fn

device = 'cuda' if torch.cuda.is_available() else 'cpu'


train_data = datasets.FashionMNIST(
    root='data',
    train=True,
    download=False,
    transform=ToTensor(),
    target_transform=None
)


img, label = train_data[0]
print(img.shape)

test_data = datasets.FashionMNIST(
    root='data',
    train=False,
    download=False,
    transform=ToTensor()
)


CLASS = len(train_data.classes)

train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)




class FashionMNISTModel(nn.Module):

    def __init__(self):
        super(FashionMNISTModel, self).__init__()
        self.flatten = nn.Flatten()
        self.linear1 = nn.Linear(in_features=784, out_features=10)
        self.linear2 = nn.Linear(in_features=10, out_features=CLASS)

    def forward(self,X):
        return self.linear2(self.linear1(self.flatten(X)))

model_v0 = FashionMNISTModel()
model_v0.to(device)


loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(params=model_v0.parameters(), lr=0.01)


epoch = 5

for i in tqdm(range(epoch)):

    train_loss = 0

    for batch, (X_train,y_train) in enumerate(train_dataloader):
        X_train, y_train = X_train.to(device), y_train.to(device)
        model_v0.train()
        print(X_train.shape)


        y_pred = model_v0(X_train)

        loss = loss_fn(y_pred, y_train)
        train_loss += loss

        optimizer.zero_grad()

        loss.backward()

        optimizer.step()

        if batch % 400 == 0:
            print(f"Looked at {batch * len(X_train)}/{len(train_dataloader)} samples")

    train_loss /= len(train_dataloader)
    test_loss, test_acc = 0, 0
    model_v0.eval()
    with torch.inference_mode():
        for X, y in test_dataloader:
            X, y = X.to(device), y.to(device)
            # 1. Forward pass
            test_pred = model_v0(X)

            # 2. Calculate loss (accumatively)
            test_loss += loss_fn(test_pred, y)  # accumulatively add up the loss per epoch

            # 3. Calculate accuracy (preds need to be same as y_true)
            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))

        # Calculations on test metrics need to happen inside torch.inference_mode()
        # Divide total test loss by length of test dataloader (per batch)
        test_loss /= len(test_dataloader)

        # Divide total accuracy by length of test dataloader (per batch)
        test_acc /= len(test_dataloader)

    ## Print out what's happening
    print(f"\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\n")


torch.save(model_v0.state_dict(), "03_pytorch_fashion.pth")

print(test_data)
model_load = FashionMNISTModel()
model_load.load_state_dict(torch.load("03_pytorch_fashion.pth"))
model_load.to(device)
model_load.eval()
img,label = test_data[1009]
img.to(device)
pred = model_load(img)
pred_softmax = torch.softmax(pred, dim=1)
idx = pred_softmax.argmax(dim=1)
print("True label", label)
print("pred label", idx)
print("Pred name",test_data.classes[idx])
print("True name",test_data.classes[label])

